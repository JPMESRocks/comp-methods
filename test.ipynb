{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Th          Ph         E  NrHits  NrBumps        E1      E1E9  \\\n",
      "0       50.8457   -0.008022  1.673710      19        1  1.055470  0.667862   \n",
      "1       22.9273 -119.515000  4.698040      19        1  2.908490  0.641230   \n",
      "2      130.3010 -126.725000  2.773130      17        1  1.826860  0.680077   \n",
      "3      160.2830   59.330500  3.099390      20        1  2.171110  0.735619   \n",
      "4       89.4000  -15.521300  3.194310      21        1  2.400890  0.774224   \n",
      "...         ...         ...       ...     ...      ...       ...       ...   \n",
      "86867  125.2240  -51.632400  0.646651      11        1  0.406012  0.661388   \n",
      "86868   48.2575   23.305300  1.096160      19        1  0.514298  0.558028   \n",
      "86869   92.8038  -43.532700  0.995061      15        1  0.423894  0.457717   \n",
      "86870  119.4840  128.111000  0.229870      14        1  0.076507  0.492713   \n",
      "86871  109.1130 -171.772000  0.437142       9        1  0.187270  0.483033   \n",
      "\n",
      "          E9E25       Z20       Z53    LatMom  type  \n",
      "0      0.960176  0.970492  0.003752  0.372940     1  \n",
      "1      0.975758  0.978056  0.000140  0.674813     1  \n",
      "2      0.976782  0.974232  0.003527  0.303936     1  \n",
      "3      0.967568  0.970230  0.000979  0.690777     1  \n",
      "4      0.978969  0.974945  0.000703  0.882015     1  \n",
      "...         ...       ...       ...       ...   ...  \n",
      "86867  0.961725  0.960797  0.001582  0.880944     0  \n",
      "86868  0.919423  0.868519  0.008453  0.982199     0  \n",
      "86869  0.956714  0.944732  0.008081  0.712000     0  \n",
      "86870  0.956878  0.325275  0.066628  0.996153     0  \n",
      "86871  0.974882  0.851031  0.019229  0.966625     0  \n",
      "\n",
      "[86872 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt                         # plotting\n",
    "import seaborn as sn  \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import cluster\n",
    "from sklearn import neighbors               # includes kNN!\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from random import randrange\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# names=['Th','Ph','E','NrHits','NrBumps','E1','E1E9','E9E25','Z20','Z53','LatMom'], delimiter=','\n",
    "emc_gam  = pd.read_csv(\"https://drive.google.com/uc?export=download&id=1TvbbCV-kJeNMuIORMyiMFgH_u_CQSZhX\")\n",
    "emc_neutron = pd.read_csv(\"https://drive.google.com/uc?export=download&id=1bY6ZPF3WLxfviYSSViuw1SEx1_sWxP46\")\n",
    "\n",
    "# This is needed for training the model. It has to know if it's right.\n",
    "emc_gam[\"type\"] = 1\n",
    "emc_neutron[\"type\"] = 0\n",
    "\n",
    "# Shove them into one big dataset for faster plotting.\n",
    "dataset = pd.concat([emc_gam, emc_neutron],ignore_index=True)\n",
    "\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing our data set \n",
    "\n",
    "dataset['E'] = ( dataset.E - dataset.E.mean() ) / dataset.E.std()\n",
    "dataset['E1']        = ( dataset.E1        - dataset.E1.mean() )        / dataset.E1.std()\n",
    "dataset['NrHits']     = ( dataset.NrHits     - dataset.NrHits.mean() )     / dataset.NrHits.std()\n",
    "dataset['E1E9']       = ( dataset.E1E9       - dataset.E1E9.mean() )       / dataset.E1E9.std()\n",
    "\n",
    "dataset['Th']       = ( dataset.Th       - dataset.Th.mean() )       / dataset.Th.std()\n",
    "dataset['Ph']       = ( dataset.Ph       - dataset.Ph.mean() )       / dataset.Ph.std()\n",
    "dataset['NrBumps']       = ( dataset.NrBumps       - dataset.NrBumps.mean() )       / dataset.NrBumps.std()\n",
    "dataset['E9E25']       = ( dataset.E9E25       - dataset.E9E25.mean() )       / dataset.E9E25.std()\n",
    "dataset['Z20']       = ( dataset.Z20       - dataset.Z20.mean() )       / dataset.Z20.std()\n",
    "dataset['Z53']       = ( dataset.Z53       - dataset.Z53.mean() )       / dataset.Z53.std()\n",
    "dataset['LatMom']       = ( dataset.LatMom       - dataset.LatMom.mean() )       / dataset.LatMom.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FOM(p, r):\n",
    "    \"\"\"\"This fucntion will return the value of the figure of merit (FOM)\n",
    "    p = model prediction\n",
    "    r = what it actually is (reality)\n",
    "    \"\"\"\n",
    "    signal = np.sum((p + r) ==2 ) # If both P and R are 1 then it's added up. AKA if it's predicted correctly.\n",
    "    background = np.sum(p) - signal # \n",
    "\n",
    "    return signal /(signal + background)**1/2\n",
    "\n",
    "\n",
    "\n",
    "def fit(dataset, parameter, test_size, classifier):\n",
    "\n",
    "    ''' \n",
    "    This function will return arrays for the test and train data set for our data, given the most powerful parameters. \n",
    "    Moreover, it will also return the FOMs from the train and test data predictions. \n",
    "\n",
    "    Arguments:\n",
    "        dataset     (pandas.DataFrame)      https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.htm. This should be the dataframe containing the data\n",
    "        parameter   (array-like)            The columns in the given data frame that you wanna use.\n",
    "        test_size   (float)                 The portion (0-1) of the test data.\n",
    "        classifier  (sklearn classifier)    Whatever classifier you wanna use for the fit.\n",
    "    Return:\n",
    "        result_te   (np.array)              The result of the test data in a numpy array.\n",
    "        result_tr   (np.array)              The result of the train data in a numpy array.\n",
    "    '''\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(dataset[parameter], dataset[['type']],test_size=test_size)\n",
    "\n",
    "    classifier.fit(np.array(X_train), np.array(Y_train))\n",
    "\n",
    "    Y_pred_train = classifier.predict(np.array(X_train))\n",
    "    X_train['p']= Y_pred_train\n",
    "    result_tr = X_train\n",
    "\n",
    "    Y_pred_test = classifier.predict(np.array(X_test))\n",
    "    X_test['p']= Y_pred_test\n",
    "    result_te = X_test\n",
    "    \n",
    "\n",
    "    return np.array(result_te), np.array(result_tr), FOM(np.array(Y_pred_test), np.array(Y_test)), FOM(np.array(Y_pred_train), np.array(Y_train))\n",
    "\n",
    "def ML(dataset,feats, vals, classifier, **kwargs):\n",
    "    ''' \n",
    "    This function will return the fom, for different calssifiers, for test and train. \n",
    "\n",
    "    Arguments:\n",
    "        dataset     (pandas.DataFrame)     https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.htm. This should be the dataframe containing the data\n",
    "        feats       (array-like)           parameters that are used for the machine learning classifier\n",
    "        vals        (array-like)           Values for the first parameter of the classifier. Usually stuff like number of neighbors or number of trees or whatever.\n",
    "        classifier  (sklearn classifier)   Whatever classifier you wanna use for the fit.                       \n",
    "        **kwargs    (any)                  Any keyword arguments that you want to pass to your classifier \n",
    "    Returns:\n",
    "        fom_te   (np.array)              The array stores all the FOMs, from where the max arg will be taken.\n",
    "        fom_tr   (np.array)              The array stores all the FOMs, from where the max arg will be taken.\n",
    "    ''' \n",
    "\n",
    "    result_te = np.empty((len(vals),len(dataset)//2,len(feats)+1))\n",
    "    result_tr = np.empty((len(vals),len(dataset)//2,len(feats)+1))\n",
    "    fom_te = np.empty(len(vals))\n",
    "    fom_tr = np.empty(len(vals))\n",
    "\n",
    "    classifiers = [classifier(i,**kwargs) for i in vals]\n",
    "\n",
    "\n",
    "    for i,k in enumerate(classifiers):\n",
    "        try:\n",
    "            result_te[i], result_tr[i], fom_te[i], fom_tr[i] = fit(dataset,feats,0.5,k)\n",
    "            print(vals[k])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "\n",
    "    max=np.argmax(fom_te)\n",
    "    print(\"test: \",vals[max], fom_te[max])\n",
    "\n",
    "    max=np.argmax(fom_tr)\n",
    "    print(\"train: \",vals[max], fom_tr[max])\n",
    "    \n",
    "    return fom_te, fom_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\mikel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "feats=['E','NrHits','E9E25','Z20','LatMom']\n",
    "k_vals = np.arange(0,20,2)\n",
    "\n",
    "def VaryingFeatures(k_vals, feats):\n",
    "    for features in range(1):\n",
    "        feats=['E','NrHits']\n",
    "\n",
    "        #kN Optimizing\n",
    "        kNfoms=ML(dataset,feats,k_vals,KNeighborsClassifier, weights='distance')\n",
    "\n",
    "        #Plotting kN\n",
    "        plt.figure(figsize = (10,10))\n",
    "        plt.title(f\"{features}\")\n",
    "        plt.plot(k_vals, kNfoms[0], label = \"test\")\n",
    "        plt.plot(k_vals, kNfoms[1], label = \"train\")\n",
    "        plt.xlabel(\"n_neighbours\" )\n",
    "        plt.ylabel(\"FOM\")\n",
    "        plt.legend()\n",
    "        fig=plt.gcf()\n",
    "        plt.show()\n",
    "        fig.savefig(f\"kNfoms_2-20\")\n",
    "\n",
    "VaryingFeatures(k_vals, feats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8a4ee24f0046a4ddd58ebd11b30d54486de2353647e5ee0d1a2aa44fd8ada2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
